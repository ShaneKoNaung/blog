[
  {
    "objectID": "posts/mlflow/experiment_tracking.html",
    "href": "posts/mlflow/experiment_tracking.html",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "In this tutorial, we are going to train a simple regression model. While training a model, we are going to use an experiment tracking tool called mlflow.\nWhat is mlflow?\nMLflow is a open-source experiment tracking tool. We can use mlflow to track experiments, experiment runs, artifacts related to experiment runs. MLflow has five components:\n- MLflow Tracking\n- MLflow Models\n- MLflow Model Registry\n- MLflow Projects\n- MLflow Recipes\nWe are only going to use Tracking, Models and Model Registry here. You can see the rest here in the mlflow docs.\nThis blog or notebook is the notes for week 2 ( experiment tracking ) lectures of the datatalks mlops zoomcamp.\n\n\nWe can install mlflow using pip or conda.\n\n# !pip install mlflow \n\n# or \n\n# !conda install -c conda-forge mlflow\n\n\n\n\nHere we are going to import a list of libraries that we need for this tutorial.\n\n!python --version\n\nPython 3.9.0\n\n\n\nfrom fastdownload import download_url\nfrom pathlib import Path\nimport pandas as pd\n\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.metrics import mean_squared_error \n\nimport mlflow\nfrom mlflow.models.signature import infer_signature\n\n\n\n\nBefore starting any training or data preprocessing, we start by setting tracking uri and experiment for this mlflow experiment. Tracking uri can be\n- localhost\n- localhost with SQlite\n- localhost with tracking server\n- remote tracking server, backend and artifact stores\nIn this tutorial, we will start with localhost option and we will also use remote tracking server option in the second half of this tutorial.\n\n\n\nIn a localhost setting, the backend and artifact store share a local folder called ./mlruns.\n\nmlflow.set_tracking_uri(\"mlruns\")\nmlflow.set_experiment(\"Experiment-1\")\n\n2023/07/17 18:58:07 INFO mlflow.tracking.fluent: Experiment with name 'Experiment-1' does not exist. Creating a new experiment.\n\n\n&lt;Experiment: artifact_location='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571', creation_time=1689596887482, experiment_id='280918629490989571', last_update_time=1689596887482, lifecycle_stage='active', name='Experiment-1', tags={}&gt;\n\n\nmlflow.set_experiment() is for setting the experiment name and we can see that a new experiment is created.\n\n!tree .\n\n.\n├── env.yaml\n├── experiment_tracking.ipynb\n├── imgs\n│   ├── mlflow_run1.png\n│   ├── mlflow_ui.png\n│   ├── model.png\n│   └── run1_metadata.png\n└── mlruns\n    ├── 0\n    │   └── meta.yaml\n    └── 280918629490989571\n        └── meta.yaml\n\n4 directories, 8 files\n\n\nWe can run mlflow ui in terminal to access, well, mlflow ui.\n:\n\n\n\nThe dataset that we are using for this tutorial is NYC TLC Trip Record dataset.\nWe are going to predict duration of a taxi ride.\n\ndata_path = Path('data')\nif not data_path.exists():\n    data_path.mkdir(exist_ok=True)\n\nFirst, we are creating a data folder data to which we are going to download the datasets.\n\ndef download_data(year : int, month : int, data_path : Path) -&gt; None:\n    '''download nyc green taxi data in parquet form and save it in data_path'''\n    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{year}-{month:0&gt;2}.parquet\"\n    download_url(url, dest=data_path, show_progress=True)\n\ndownload_data(2023, 1, data_path)\ndownload_data(2023, 2, data_path)\n\n\n\n\n\n\n    \n      \n      100.46% [1433600/1427002 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.41% [1540096/1533740 00:01&lt;00:00]\n    \n    \n\n\nQuick side note for pyformatting,\n\nmonth = 2\nprint(f\"month == {month} : {month:0&gt;2}\")\n\nmonth = 11\nprint(f\"month == {month} : {month:0&gt;2}\")\n\nmonth == 2 : 02\nmonth == 11 : 11\n\n\n\n!tree .\n\n.\n├── data\n│   ├── green_tripdata_2023-01.parquet\n│   └── green_tripdata_2023-02.parquet\n├── env.yaml\n├── experiment_tracking.ipynb\n├── imgs\n│   ├── mlflow_run1.png\n│   ├── mlflow_ui.png\n│   ├── model.png\n│   └── run1_metadata.png\n└── mlruns\n    ├── 0\n    │   └── meta.yaml\n    └── 280918629490989571\n        └── meta.yaml\n\n5 directories, 10 files\n\n\nDatasets are downloaded using fastdownload library from fastai.\n\n\n\n\ndef read_dataframe(filename: Path)-&gt; pd.DataFrame:\n    df = pd.read_parquet(filename)\n    df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]\n    df.duration = df[\"duration\"].apply(lambda td : td.total_seconds() / 60)\n    df = df[(df.duration  &gt;= 0) & (df.duration &lt;= 60) ]\n\n    categorical_data = [\"PULocationID\", \"DOLocationID\"]\n    df[categorical_data] = df[categorical_data].astype(str)\n    df[\"PU_DO\"] = df['PULocationID'] + \"_\" + df['DOLocationID']\n\n    return df\n\nSince the files are in parquet format, we use pd.read_parquet() method.\n\n# df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]\n# df.duration = df[\"duration\"].apply(lambda td : td.total_seconds() / 60)\n\nWe want to calculate the duration of each trip. The trip duration is calculated by subtracting pickup datetime from dropoff datetime.\nWe also want to get the duration in minute. We get the total seconds and divided by 60.\n\ndf = read_dataframe(\"data/green_tripdata_2023-01.parquet\")\ndf_val = read_dataframe(\"data/green_tripdata_2023-02.parquet\")\n\n\ndef preprocess(df : pd.DataFrame) -&gt; tuple((pd.DataFrame, pd.DataFrame)):\n    categorical = [\"PU_DO\"]\n    numerical   = [\"trip_distance\", \"fare_amount\", \"total_amount\"]\n\n    X = df[categorical + numerical]\n    y = df.duration\n\n    return X, y\n    \n\n\nX, y = preprocess(df)\nX_val, y_val = preprocess(df_val)\n\nAfter loading train and validation dataset and performing preprocessing, we now have features X and targets y.\nNow we can start training the model.\n\n\n\n\ndef train(X, y):\n    model = LinearRegression()\n    model.fit(X,y)\n\n    return model\n\nWe will initialize mlflow run as\n\n# with mlflow.start_run() as run:\n\nand wrap up the training inside of it.\n- `set_tag` : for tracking metadata\n- `log_param` : for logging parameters\n- `log_metric` : for logging metric\nIn the example below, we use set_tag for tracking developer name, log_param for tracking data folder used for training and validation ,and log_metric for tracking validation rmse metric.\nSome other useful methods are :\n- `set_tags` : Log a batch of tags for the current run.\n- `log_params` : Log a batch of params for the current run.\n- `log_artifact` : Log a local file or directory as an artifact of the currently active run.\n- `log_artifacts` : Log all the contents of a local directory as artifacts of the run\n\nwith mlflow.start_run() as run:\n\n    mlflow.set_tag(\"Developer\", \"Shane\")\n    mlflow.log_param(\"Train-data-path\", \"data/green_tripdata_2023-01.parquet\")\n    mlflow.log_param(\"Valid-data-path\", \"data/green_tripdata_2023-02.parquet\")\n    \n    model = train(X, y)\n\n    preds = model.predict(X_val)\n\n    rmse = mean_squared_error(y_val, preds, squared=False)\n\n    mlflow.log_metric('RMSE', rmse)\n    signature = infer_signature(X_val, preds)\n    model_uri = mlflow.sklearn.log_model(model, artifact_path=\"model\", signature=signature).model_uri\n   \n\n\n\n\nfist run\n\n\nThe first run can be seen in the above picture with the name, shivering-panda-266. It is a random run name since we didn’t set a specific run name.\n\n\n\nrun1\n\n\nWe can see the Train-data-path, Valid-data-path in the Parameters section, RMSE in metrics section and Developer in the Tags section.\n\n\n\n\n# signature = infer_signature(X_val, preds)\n# mlflow.sklearn.log_model(model, artifact_path=\"model\", signature=signature)\n\nModel signatures define input and output schemas for MLflow models. Model signature is obtained here using infer_signature.\nWe can log a model using mlflow.&lt;framework&gt;.log_model. In this case, we are using mlflow.sklearn.log_model.\n\n\n\nmodel1\n\n\nSince we add signature parameter, we can see the model input and output schema here. We can also see two ways that we can load the model and make predictions.\n\n\n\nWe can also do auto logging by using mlflow.&lt;framework&gt;.autolog()\n\n# mlflow.sklearn.autolog()\n\nAutologging is known to be compatible with the following package versions: 0.22.1 &lt;= scikit-learn &lt;= 1.2.2. Autologging may not succeed when used with package versions outside of this range.\n\n\n\nWe have saved the model using log_model. Now, we are going to load that model for prediction.\n\nfrom mlflow import MlflowClient\n\nclient = MlflowClient(tracking_uri=\"mlruns\")\n\n\nexperiments = client.search_experiments()\n\nfor experiment in experiments:\n    print(f\"Experiment Name : {experiment.name}\")\n    print(f\"\\tExperiment id :{experiment.experiment_id}\")\n    print(f\"\\tArtifact Location :{experiment.artifact_location}\\n\")\n\nExperiment Name : Experiment-1\n    Experiment id :280918629490989571\n    Artifact Location :/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571\n\nExperiment Name : Default\n    Experiment id :0\n    Artifact Location :/home/shane/mlops-practice/experiment-tracking/mlruns/0\n\n\n\nOur experiment’s name is “Experiment-1” and the Experiment id for that is “146920015920581846”.\n\nfor experiment in experiments:\n    if experiment.name == \"Experiment-1\":\n        exp = experiment\n\n\nexp_id = exp.experiment_id\nruns = client.search_runs(experiment_ids=[exp_id])\n\nfor run in runs:\n    print(f\"run name : {run.info.run_name}\")\n    print(f\"\\trun id : {run.info.run_id}\")\n    print(f\"\\trmse : {run.data.metrics['RMSE']}\")\n\nrun name : charming-toad-155\n    run id : 9ed0390d8a4b44dca36f36ee25d20ba4\n    rmse : 6.282692349434918\n\n\nLet’s pick a run_id of the model that we want to load.\n\nrun_id = runs[0].info.run_id\nlogged_model = f'runs:/{run_id}/model'\n\n# Load model as a PyFuncModel.\nloaded_model = mlflow.pyfunc.load_model(logged_model)\n\n# Predict on a Pandas DataFrame.\nimport pandas as pd\nloaded_model.predict(X_val)\n\n2023/07/17 18:59:06 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - mlflow (current: 2.4.2, required: mlflow==2.4)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n\n\narray([26.09040939, 16.31353026, 22.14756441, ..., 15.42763737,\n       14.91915344, 12.24746033])\n\n\n\n\n\nModel Registry is a centralized model store, a set of APIs and UI. It provides\n    - model lineage, \n    - model versioning, \n    - stage transition, and \n    - annotations.\n\nmlflow.set_tracking_uri('mlruns/')\n\nmodel_uri = f\"runs:/{run_id}/models\"\nmlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")\n\nSuccessfully registered model 'nyc-taxi-regressor'.\n2023/07/17 18:59:10 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: nyc-taxi-regressor, version 1\nCreated version '1' of model 'nyc-taxi-regressor'.\n\n\n&lt;ModelVersion: aliases=[], creation_timestamp=1689596950866, current_stage='None', description=None, last_updated_timestamp=1689596950866, name='nyc-taxi-regressor', run_id='9ed0390d8a4b44dca36f36ee25d20ba4', run_link=None, source='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571/9ed0390d8a4b44dca36f36ee25d20ba4/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1&gt;\n\n\nWe have now registered the model under the name of “nyc-taxi-regressor’.\nWe can see that the version of the model is now 1. Since this is the first model registered under this name.\nBut It doesn’t have any staging information.\n\nmodel_name = \"nyc-taxi-regressor\"\nlatest_versions = client.get_latest_versions(name=model_name)\n\nfor version in latest_versions:\n    print(f\"version: {version.version}, stage: {version.current_stage}\")\n\nversion: 1, stage: None\n\n\nWe can transition the model version and stages using transition_model_version_stage.\n\nmodel_version = 1\nnew_stage = \"Staging\"\nclient.transition_model_version_stage(\n    name=model_name,\n    version=model_version,\n    stage=new_stage,\n    archive_existing_versions=False\n)\n\n&lt;ModelVersion: aliases=[], creation_timestamp=1689596950866, current_stage='Staging', description=None, last_updated_timestamp=1689596955099, name='nyc-taxi-regressor', run_id='9ed0390d8a4b44dca36f36ee25d20ba4', run_link=None, source='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571/9ed0390d8a4b44dca36f36ee25d20ba4/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1&gt;\n\n\n\nmodel_name = \"nyc-taxi-regressor\"\nlatest_versions = client.get_latest_versions(name=model_name)\n\nfor version in latest_versions:\n    print(f\"version: {version.version}, stage: {version.current_stage}\")\n\nversion: 1, stage: Staging\n\n\nNow, we can see that the stage of the model is now Staging.\n\nfrom datetime import datetime\n\ndate = datetime.today().date()\nclient.update_model_version(\n    name=model_name,\n    version=model_version,\n    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n)\n\n&lt;ModelVersion: aliases=[], creation_timestamp=1689596950866, current_stage='Staging', description='The model version 1 was transitioned to Staging on 2023-07-17', last_updated_timestamp=1689596958723, name='nyc-taxi-regressor', run_id='9ed0390d8a4b44dca36f36ee25d20ba4', run_link=None, source='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571/9ed0390d8a4b44dca36f36ee25d20ba4/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1&gt;\n\n\nWe could also add description of the models like datetime information above."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#install",
    "href": "posts/mlflow/experiment_tracking.html#install",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "We can install mlflow using pip or conda.\n\n# !pip install mlflow \n\n# or \n\n# !conda install -c conda-forge mlflow"
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#imports",
    "href": "posts/mlflow/experiment_tracking.html#imports",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "Here we are going to import a list of libraries that we need for this tutorial.\n\n!python --version\n\nPython 3.9.0\n\n\n\nfrom fastdownload import download_url\nfrom pathlib import Path\nimport pandas as pd\n\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.metrics import mean_squared_error \n\nimport mlflow\nfrom mlflow.models.signature import infer_signature"
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#tracking-uri",
    "href": "posts/mlflow/experiment_tracking.html#tracking-uri",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "Before starting any training or data preprocessing, we start by setting tracking uri and experiment for this mlflow experiment. Tracking uri can be\n- localhost\n- localhost with SQlite\n- localhost with tracking server\n- remote tracking server, backend and artifact stores\nIn this tutorial, we will start with localhost option and we will also use remote tracking server option in the second half of this tutorial."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#localhost",
    "href": "posts/mlflow/experiment_tracking.html#localhost",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "In a localhost setting, the backend and artifact store share a local folder called ./mlruns.\n\nmlflow.set_tracking_uri(\"mlruns\")\nmlflow.set_experiment(\"Experiment-1\")\n\n2023/07/17 18:58:07 INFO mlflow.tracking.fluent: Experiment with name 'Experiment-1' does not exist. Creating a new experiment.\n\n\n&lt;Experiment: artifact_location='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571', creation_time=1689596887482, experiment_id='280918629490989571', last_update_time=1689596887482, lifecycle_stage='active', name='Experiment-1', tags={}&gt;\n\n\nmlflow.set_experiment() is for setting the experiment name and we can see that a new experiment is created.\n\n!tree .\n\n.\n├── env.yaml\n├── experiment_tracking.ipynb\n├── imgs\n│   ├── mlflow_run1.png\n│   ├── mlflow_ui.png\n│   ├── model.png\n│   └── run1_metadata.png\n└── mlruns\n    ├── 0\n    │   └── meta.yaml\n    └── 280918629490989571\n        └── meta.yaml\n\n4 directories, 8 files\n\n\nWe can run mlflow ui in terminal to access, well, mlflow ui.\n:"
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#downloading-dataset",
    "href": "posts/mlflow/experiment_tracking.html#downloading-dataset",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "The dataset that we are using for this tutorial is NYC TLC Trip Record dataset.\nWe are going to predict duration of a taxi ride.\n\ndata_path = Path('data')\nif not data_path.exists():\n    data_path.mkdir(exist_ok=True)\n\nFirst, we are creating a data folder data to which we are going to download the datasets.\n\ndef download_data(year : int, month : int, data_path : Path) -&gt; None:\n    '''download nyc green taxi data in parquet form and save it in data_path'''\n    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{year}-{month:0&gt;2}.parquet\"\n    download_url(url, dest=data_path, show_progress=True)\n\ndownload_data(2023, 1, data_path)\ndownload_data(2023, 2, data_path)\n\n\n\n\n\n\n    \n      \n      100.46% [1433600/1427002 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.41% [1540096/1533740 00:01&lt;00:00]\n    \n    \n\n\nQuick side note for pyformatting,\n\nmonth = 2\nprint(f\"month == {month} : {month:0&gt;2}\")\n\nmonth = 11\nprint(f\"month == {month} : {month:0&gt;2}\")\n\nmonth == 2 : 02\nmonth == 11 : 11\n\n\n\n!tree .\n\n.\n├── data\n│   ├── green_tripdata_2023-01.parquet\n│   └── green_tripdata_2023-02.parquet\n├── env.yaml\n├── experiment_tracking.ipynb\n├── imgs\n│   ├── mlflow_run1.png\n│   ├── mlflow_ui.png\n│   ├── model.png\n│   └── run1_metadata.png\n└── mlruns\n    ├── 0\n    │   └── meta.yaml\n    └── 280918629490989571\n        └── meta.yaml\n\n5 directories, 10 files\n\n\nDatasets are downloaded using fastdownload library from fastai."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#preprocessing",
    "href": "posts/mlflow/experiment_tracking.html#preprocessing",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "def read_dataframe(filename: Path)-&gt; pd.DataFrame:\n    df = pd.read_parquet(filename)\n    df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]\n    df.duration = df[\"duration\"].apply(lambda td : td.total_seconds() / 60)\n    df = df[(df.duration  &gt;= 0) & (df.duration &lt;= 60) ]\n\n    categorical_data = [\"PULocationID\", \"DOLocationID\"]\n    df[categorical_data] = df[categorical_data].astype(str)\n    df[\"PU_DO\"] = df['PULocationID'] + \"_\" + df['DOLocationID']\n\n    return df\n\nSince the files are in parquet format, we use pd.read_parquet() method.\n\n# df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]\n# df.duration = df[\"duration\"].apply(lambda td : td.total_seconds() / 60)\n\nWe want to calculate the duration of each trip. The trip duration is calculated by subtracting pickup datetime from dropoff datetime.\nWe also want to get the duration in minute. We get the total seconds and divided by 60.\n\ndf = read_dataframe(\"data/green_tripdata_2023-01.parquet\")\ndf_val = read_dataframe(\"data/green_tripdata_2023-02.parquet\")\n\n\ndef preprocess(df : pd.DataFrame) -&gt; tuple((pd.DataFrame, pd.DataFrame)):\n    categorical = [\"PU_DO\"]\n    numerical   = [\"trip_distance\", \"fare_amount\", \"total_amount\"]\n\n    X = df[categorical + numerical]\n    y = df.duration\n\n    return X, y\n    \n\n\nX, y = preprocess(df)\nX_val, y_val = preprocess(df_val)\n\nAfter loading train and validation dataset and performing preprocessing, we now have features X and targets y.\nNow we can start training the model."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#model-training",
    "href": "posts/mlflow/experiment_tracking.html#model-training",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "def train(X, y):\n    model = LinearRegression()\n    model.fit(X,y)\n\n    return model\n\nWe will initialize mlflow run as\n\n# with mlflow.start_run() as run:\n\nand wrap up the training inside of it.\n- `set_tag` : for tracking metadata\n- `log_param` : for logging parameters\n- `log_metric` : for logging metric\nIn the example below, we use set_tag for tracking developer name, log_param for tracking data folder used for training and validation ,and log_metric for tracking validation rmse metric.\nSome other useful methods are :\n- `set_tags` : Log a batch of tags for the current run.\n- `log_params` : Log a batch of params for the current run.\n- `log_artifact` : Log a local file or directory as an artifact of the currently active run.\n- `log_artifacts` : Log all the contents of a local directory as artifacts of the run\n\nwith mlflow.start_run() as run:\n\n    mlflow.set_tag(\"Developer\", \"Shane\")\n    mlflow.log_param(\"Train-data-path\", \"data/green_tripdata_2023-01.parquet\")\n    mlflow.log_param(\"Valid-data-path\", \"data/green_tripdata_2023-02.parquet\")\n    \n    model = train(X, y)\n\n    preds = model.predict(X_val)\n\n    rmse = mean_squared_error(y_val, preds, squared=False)\n\n    mlflow.log_metric('RMSE', rmse)\n    signature = infer_signature(X_val, preds)\n    model_uri = mlflow.sklearn.log_model(model, artifact_path=\"model\", signature=signature).model_uri\n   \n\n\n\n\nfist run\n\n\nThe first run can be seen in the above picture with the name, shivering-panda-266. It is a random run name since we didn’t set a specific run name.\n\n\n\nrun1\n\n\nWe can see the Train-data-path, Valid-data-path in the Parameters section, RMSE in metrics section and Developer in the Tags section."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#model-saving",
    "href": "posts/mlflow/experiment_tracking.html#model-saving",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "# signature = infer_signature(X_val, preds)\n# mlflow.sklearn.log_model(model, artifact_path=\"model\", signature=signature)\n\nModel signatures define input and output schemas for MLflow models. Model signature is obtained here using infer_signature.\nWe can log a model using mlflow.&lt;framework&gt;.log_model. In this case, we are using mlflow.sklearn.log_model.\n\n\n\nmodel1\n\n\nSince we add signature parameter, we can see the model input and output schema here. We can also see two ways that we can load the model and make predictions."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#auto-logging",
    "href": "posts/mlflow/experiment_tracking.html#auto-logging",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "We can also do auto logging by using mlflow.&lt;framework&gt;.autolog()\n\n# mlflow.sklearn.autolog()\n\nAutologging is known to be compatible with the following package versions: 0.22.1 &lt;= scikit-learn &lt;= 1.2.2. Autologging may not succeed when used with package versions outside of this range."
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#model-loading",
    "href": "posts/mlflow/experiment_tracking.html#model-loading",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "We have saved the model using log_model. Now, we are going to load that model for prediction.\n\nfrom mlflow import MlflowClient\n\nclient = MlflowClient(tracking_uri=\"mlruns\")\n\n\nexperiments = client.search_experiments()\n\nfor experiment in experiments:\n    print(f\"Experiment Name : {experiment.name}\")\n    print(f\"\\tExperiment id :{experiment.experiment_id}\")\n    print(f\"\\tArtifact Location :{experiment.artifact_location}\\n\")\n\nExperiment Name : Experiment-1\n    Experiment id :280918629490989571\n    Artifact Location :/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571\n\nExperiment Name : Default\n    Experiment id :0\n    Artifact Location :/home/shane/mlops-practice/experiment-tracking/mlruns/0\n\n\n\nOur experiment’s name is “Experiment-1” and the Experiment id for that is “146920015920581846”.\n\nfor experiment in experiments:\n    if experiment.name == \"Experiment-1\":\n        exp = experiment\n\n\nexp_id = exp.experiment_id\nruns = client.search_runs(experiment_ids=[exp_id])\n\nfor run in runs:\n    print(f\"run name : {run.info.run_name}\")\n    print(f\"\\trun id : {run.info.run_id}\")\n    print(f\"\\trmse : {run.data.metrics['RMSE']}\")\n\nrun name : charming-toad-155\n    run id : 9ed0390d8a4b44dca36f36ee25d20ba4\n    rmse : 6.282692349434918\n\n\nLet’s pick a run_id of the model that we want to load.\n\nrun_id = runs[0].info.run_id\nlogged_model = f'runs:/{run_id}/model'\n\n# Load model as a PyFuncModel.\nloaded_model = mlflow.pyfunc.load_model(logged_model)\n\n# Predict on a Pandas DataFrame.\nimport pandas as pd\nloaded_model.predict(X_val)\n\n2023/07/17 18:59:06 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n - mlflow (current: 2.4.2, required: mlflow==2.4)\nTo fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n\n\narray([26.09040939, 16.31353026, 22.14756441, ..., 15.42763737,\n       14.91915344, 12.24746033])"
  },
  {
    "objectID": "posts/mlflow/experiment_tracking.html#model-registry",
    "href": "posts/mlflow/experiment_tracking.html#model-registry",
    "title": "Experiment Tracking with MLflow",
    "section": "",
    "text": "Model Registry is a centralized model store, a set of APIs and UI. It provides\n    - model lineage, \n    - model versioning, \n    - stage transition, and \n    - annotations.\n\nmlflow.set_tracking_uri('mlruns/')\n\nmodel_uri = f\"runs:/{run_id}/models\"\nmlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")\n\nSuccessfully registered model 'nyc-taxi-regressor'.\n2023/07/17 18:59:10 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: nyc-taxi-regressor, version 1\nCreated version '1' of model 'nyc-taxi-regressor'.\n\n\n&lt;ModelVersion: aliases=[], creation_timestamp=1689596950866, current_stage='None', description=None, last_updated_timestamp=1689596950866, name='nyc-taxi-regressor', run_id='9ed0390d8a4b44dca36f36ee25d20ba4', run_link=None, source='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571/9ed0390d8a4b44dca36f36ee25d20ba4/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1&gt;\n\n\nWe have now registered the model under the name of “nyc-taxi-regressor’.\nWe can see that the version of the model is now 1. Since this is the first model registered under this name.\nBut It doesn’t have any staging information.\n\nmodel_name = \"nyc-taxi-regressor\"\nlatest_versions = client.get_latest_versions(name=model_name)\n\nfor version in latest_versions:\n    print(f\"version: {version.version}, stage: {version.current_stage}\")\n\nversion: 1, stage: None\n\n\nWe can transition the model version and stages using transition_model_version_stage.\n\nmodel_version = 1\nnew_stage = \"Staging\"\nclient.transition_model_version_stage(\n    name=model_name,\n    version=model_version,\n    stage=new_stage,\n    archive_existing_versions=False\n)\n\n&lt;ModelVersion: aliases=[], creation_timestamp=1689596950866, current_stage='Staging', description=None, last_updated_timestamp=1689596955099, name='nyc-taxi-regressor', run_id='9ed0390d8a4b44dca36f36ee25d20ba4', run_link=None, source='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571/9ed0390d8a4b44dca36f36ee25d20ba4/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1&gt;\n\n\n\nmodel_name = \"nyc-taxi-regressor\"\nlatest_versions = client.get_latest_versions(name=model_name)\n\nfor version in latest_versions:\n    print(f\"version: {version.version}, stage: {version.current_stage}\")\n\nversion: 1, stage: Staging\n\n\nNow, we can see that the stage of the model is now Staging.\n\nfrom datetime import datetime\n\ndate = datetime.today().date()\nclient.update_model_version(\n    name=model_name,\n    version=model_version,\n    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n)\n\n&lt;ModelVersion: aliases=[], creation_timestamp=1689596950866, current_stage='Staging', description='The model version 1 was transitioned to Staging on 2023-07-17', last_updated_timestamp=1689596958723, name='nyc-taxi-regressor', run_id='9ed0390d8a4b44dca36f36ee25d20ba4', run_link=None, source='/home/shane/mlops-practice/experiment-tracking/mlruns/280918629490989571/9ed0390d8a4b44dca36f36ee25d20ba4/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1&gt;\n\n\nWe could also add description of the models like datetime information above."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "These are just my notes about MLOps, Machine Learning, Deep Learning and Python.\nMy Name is Shane Ko Naung.I am a machine learning engineer from Myanmar."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Data Manipulation with Pytorch\n\n\n\n\n\n\n\npytorch\n\n\nd2l\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\nShane Ko Naung\n\n\n\n\n\n\n  \n\n\n\n\nExperiment Tracking with MLflow\n\n\n\n\n\n\n\nmlops\n\n\nmlflow\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\nShane Ko Naung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html",
    "title": "Data Manipulation with Pytorch",
    "section": "",
    "text": "Notes for chapter 2 section 1 of Dive into deep learning."
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#getting-started",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#getting-started",
    "title": "Data Manipulation with Pytorch",
    "section": "Getting Started",
    "text": "Getting Started\n\nimport torch\n\n\ntensor : (possibly multi dimensional) array of numbers\ntensor with one axis : vector\ntensor with two axes : matrix\ntensor with more than two axes k &gt; 2 : kth order tensor\ncreate new tensors populated with values.\narange(n) : create a vector of evenly spaced values, starting at 0 ( included ) and ending at n ( not included ).\nBy default, the interval size is 1.\nstored in main memory for CPU based computations.\n\n\nx = torch.arange(12, dtype=torch.float32)\nx\n\ntensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n\n\n\nEach value is called element of tensor.\ncan inspect total number of elements using numel method.\n\n\nx.numel()\n\n12\n\n\n\ncan inspect shape of a tensor using shape attribute\n\n\nx.shape\n\ntorch.Size([12])\n\n\n\ncan inspect size of each dim or axis using size method\n\n\nx.size(dim=0)\n\n12\n\n\n\ncan change the shape of a tensor without altering its value using reshape method\nnew tensor becomes a matrix\n\n\nX = x.reshape(4,3)\nX, X.shape\n\n(tensor([[ 0.,  1.,  2.],\n         [ 3.,  4.,  5.],\n         [ 6.,  7.,  8.],\n         [ 9., 10., 11.]]),\n torch.Size([4, 3]))\n\n\n\nwe don’t need to specify all component of reshape.\nsince we already know the size of the tensor, we only need to specify one component.\n\n\nx.reshape(-1, 3), x.reshape(4, -1)\n\n(tensor([[ 0.,  1.,  2.],\n         [ 3.,  4.,  5.],\n         [ 6.,  7.,  8.],\n         [ 9., 10., 11.]]),\n tensor([[ 0.,  1.,  2.],\n         [ 3.,  4.,  5.],\n         [ 6.,  7.,  8.],\n         [ 9., 10., 11.]]))\n\n\n\ntensor initialized to contain all zeros or ones\n\n\ntorch.zeros((2,3,4)), torch.ones((2,3,4))\n\n(tensor([[[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n \n         [[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]]),\n tensor([[[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n \n         [[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]]]))\n\n\n\ncan also initialzed tensor with elements drawn from a standard Gaussina (normal) distribution with mean 0 and standard deviation 1.\n\n\ntorch.randn(3, 4)\n\ntensor([[ 2.3716, -0.2123, -1.0150,  1.1659],\n        [-1.8146, -0.1514,  0.0144,  0.0529],\n        [-0.0288,  0.2103,  2.7825, -1.1707]])\n\n\n\nFinally, can also construct tensors by giving exact values using (nested) python lists\n\n\ntorch.tensor([[2, 3, 4], [2,4,5]])\n\ntensor([[2, 3, 4],\n        [2, 4, 5]])"
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#indexing-and-slicing",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#indexing-and-slicing",
    "title": "Data Manipulation with Pytorch",
    "section": "Indexing and Slicing",
    "text": "Indexing and Slicing\n\nlike python list, we can access tensor elements by indexing (starting with 0)\nnegative indexing to access element based on its position relative to the end\ncan also access a whole range of elements by slicing (X [ start: end] ) , including start and not including end\nFinally, when only one index ( or slice ) is specified for a kth order tensor, it is applied along axis 0.\n\n\nX\n\ntensor([[ 0.,  1.,  2.],\n        [ 3.,  4.,  5.],\n        [ 6.,  7.,  8.],\n        [ 9., 10., 11.]])\n\n\n\nX[-1]\n\ntensor([ 9., 10., 11.])\n\n\n\nX[2:4]\n\ntensor([[ 6.,  7.,  8.],\n        [ 9., 10., 11.]])\n\n\n\nX[2,2]\n\ntensor(8.)\n\n\n\nX[2, :2]\n\ntensor([6., 7.])\n\n\n\ncan also write elements of a matrix by specifying indices\n\n\nX[2,2] = 34\n\n\nX\n\ntensor([[ 0.,  1.,  2.],\n        [ 3.,  4.,  5.],\n        [ 6.,  7., 34.],\n        [ 9., 10., 11.]])\n\n\n\nto assign multiple elements with the same value, we can use indexing on the left hand side\n\n\nX[:2, :] = 22\nX\n\ntensor([[22., 22., 22.],\n        [22., 22., 22.],\n        [ 6.,  7., 34.],\n        [ 9., 10., 11.]])"
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#operations",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#operations",
    "title": "Data Manipulation with Pytorch",
    "section": "Operations",
    "text": "Operations\n\nelementwise operations : these apply a standard scalar operation to each element of the tensor\nunary scalar operator : taking one input\n\n\ntorch.exp(x)\n\ntensor([3.5849e+09, 3.5849e+09, 3.5849e+09, 3.5849e+09, 3.5849e+09, 3.5849e+09,\n        4.0343e+02, 1.0966e+03, 5.8346e+14, 8.1031e+03, 2.2026e+04, 5.9874e+04])\n\n\n\nbinary scalar operator : taking two inputs\n\n\nx = torch.tensor([1., 2., 4. , 6.])\ny = torch.tensor([2, 2, 2, 2])\n\nx + y, x - y, x * y, x / y, x ** y\n\n(tensor([3., 4., 6., 8.]),\n tensor([-1.,  0.,  2.,  4.]),\n tensor([ 2.,  4.,  8., 12.]),\n tensor([0.5000, 1.0000, 2.0000, 3.0000]),\n tensor([ 1.,  4., 16., 36.]))\n\n\n\nconcatenate multiple tensors together : stacking them end to end to form a larger tensor.\n\n\nX = torch.arange(12, dtype=torch.float32).reshape((3,4))\nY = torch.tensor([[2., 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\ntorch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n\n(tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.],\n         [ 2.,  1.,  4.,  3.],\n         [ 1.,  2.,  3.,  4.],\n         [ 4.,  3.,  2.,  1.]]),\n tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))\n\n\n\nconstruct binary tensor via logical statements\n\n\nX == Y\n\ntensor([[False,  True, False,  True],\n        [False, False, False, False],\n        [False, False, False, False]])\n\n\n\nX &lt; Y\n\ntensor([[ True, False,  True, False],\n        [False, False, False, False],\n        [False, False, False, False]])\n\n\n\nX &gt; Y\n\ntensor([[False, False, False, False],\n        [ True,  True,  True,  True],\n        [ True,  True,  True,  True]])\n\n\n\nSumming all the elements in the tensor using sum method\n\n\nX.sum()\n\ntensor(66.)"
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#broadcasting",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#broadcasting",
    "title": "Data Manipulation with Pytorch",
    "section": "Broadcasting",
    "text": "Broadcasting\n\ncan now do elementwise binary operations on two tensors with the same shape\nBroadcasting\n\nunder certain conditions, can still perform elementwise binary operations on two tensors with different shapes\n\n\nexpand one or both arrays by copying elements along axes with length 1 so that after the transformation, the two tensors have the same shape.\nperform elementwise operations on the resulting arrays\n\n\n\n\n\na = torch.arange(3).reshape((3, 1))\nb = torch.arange(2).reshape((1,2))\na, b\n\n(tensor([[0],\n         [1],\n         [2]]),\n tensor([[0, 1]]))\n\n\n\na + b\n\ntensor([[0, 1],\n        [1, 2],\n        [2, 3]])\n\n\n\na = torch.arange(6).reshape((3, 2))\nb = torch.arange(9).reshape((3,3))\na, b\n\n(tensor([[0, 1],\n         [2, 3],\n         [4, 5]]),\n tensor([[0, 1, 2],\n         [3, 4, 5],\n         [6, 7, 8]]))\n\n\n\na + b\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\nsingleton dimensions are dimensions of size 1.\nWhat is singleton dimension of a tensor\n\n\na = torch.ones((2,3,3))\nb = torch.ones((1,1,3))\n\na, b\n\n(tensor([[[1., 1., 1.],\n          [1., 1., 1.],\n          [1., 1., 1.]],\n \n         [[1., 1., 1.],\n          [1., 1., 1.],\n          [1., 1., 1.]]]),\n tensor([[[1., 1., 1.]]]))\n\n\n\na + b\n\ntensor([[[2., 2., 2.],\n         [2., 2., 2.],\n         [2., 2., 2.]],\n\n        [[2., 2., 2.],\n         [2., 2., 2.],\n         [2., 2., 2.]]])\n\n\n\nhow-does-pytorch-broadcasting-work\nPytorch broadcasting semantics\nNumpy Broadcasting Rules"
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#saving-memory",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#saving-memory",
    "title": "Data Manipulation with Pytorch",
    "section": "Saving Memory",
    "text": "Saving Memory\n\nrunning operations can cause new memories to be allocated to host results.\nby running Y = Y + X, python dereference the tensor that Y used to point to and instead point Y at the newly allocated memory.\n\n\nbefore = id(Y)\nY = Y + X\nid(Y) == before\n\nFalse\n\n\n\nThis is how to do operations in place.\nno unnecessary memeory allocations\nwe can avoid a memory leak or referring to stale parameters\n\n\nZ = torch.zeros_like(Y)\nprint(f'id(Z) : {id(Z)}')\nZ[:] = X + Y\nprint(f'id(Z) : {id(Z)}')\n\nid(Z) : 140466157769232\nid(Z) : 140466157769232\n\n\n\nbefore = id(X)\nX += Y\nid(X) == before\n\nTrue"
  },
  {
    "objectID": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#conversion-to-other-python-objects",
    "href": "posts/data_manipulation_d2l/2.1-Data_Manipulation.html#conversion-to-other-python-objects",
    "title": "Data Manipulation with Pytorch",
    "section": "Conversion to other python objects",
    "text": "Conversion to other python objects\n\nnumpy to torch , torch to numpy\n\n\nA = X.numpy()\nB = torch.from_numpy(A)\ntype(A), type(B)\n\n(numpy.ndarray, torch.Tensor)\n\n\n\nto convert size one torch tensor to python scalar\n\nitem function\npython built-in functions\n\n\n\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n\n(tensor([3.5000]), 3.5, 3.5, 3)"
  }
]